# =============================================================================
# NETWORKLY ENVIRONMENT CONFIGURATION
# =============================================================================
# Copy this file to .env and fill in your values
# cp .env.example .env
# =============================================================================

# =============================================================================
# AUTHENTICATION (Clerk)
# =============================================================================
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=pk_test_...
CLERK_SECRET_KEY=sk_test_...

# =============================================================================
# DATABASE (Supabase)
# =============================================================================
NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJ...
SUPABASE_SERVICE_ROLE_KEY=eyJ...

# =============================================================================
# AI PROVIDERS (Required - at least one)
# =============================================================================
# The app uses AI for opportunity discovery and the assistant.
# You need at least ONE of these API keys.

# Google Gemini (Required by @ai-sdk/google)
# Get your key at: https://aistudio.google.com/apikey
GOOGLE_GENERATIVE_AI_API_KEY="AIza..."

# Google Vertex AI (Alternative to API Key - Recommended for Production)
GOOGLE_VERTEX_PROJECT="your-gcp-project-id"
GOOGLE_VERTEX_LOCATION="us-central1"
# GOOGLE_APPLICATION_CREDENTIALS_JSON="{...}" # Optional: Inline JSON credentials

# OpenRouter (Optional - Access to many models)
# Get your key at: https://openrouter.ai/keys
# OPENROUTER_API_KEY="sk-or-..."

# =============================================================================
# SCRAPER SERVICE (Cloud Run)
# =============================================================================
# URL where the Python scraper is deployed
SCRAPER_API_URL="http://localhost:8080" # Dev: localhost, Prod: https://scraper-xyz.a.run.app

# Shared secret for securing communication between frontend and scraper
DISCOVERY_API_TOKEN="your-secure-token-32-chars"

# Secret for triggering daily cron jobs via API
CRON_SECRET="your-cron-secret-64-chars"

# =============================================================================
# OPTIONAL SETTINGS
# =============================================================================

# Application URL (change in production)
NEXT_PUBLIC_APP_URL=http://localhost:3000

# AI Request timeout in milliseconds (default: 30000)
AI_TIMEOUT=30000

# Maximum AI retry attempts (default: 3)
AI_MAX_RETRIES=3
